{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.remove('/usr/local/lib/python3.7/site-packages')\n",
    "sys.path.append('/usr/local/.pyenv/versions/3.6.0/lib/python3.6/site-packages')\n",
    "sys.path.append('/Users/kazuya_yufune/.pyenv/versions/3.6.0/lib/python3.6/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import expanduser, join\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "import time\n",
    "\n",
    "from nnmnkwii.datasets import FileDataSource, FileSourceDataset\n",
    "from nnmnkwii.datasets import PaddedFileSourceDataset, MemoryCacheDataset  # これはなに？\n",
    "from nnmnkwii.preprocessing import trim_zeros_frames, remove_zeros_frames\n",
    "from nnmnkwii.preprocessing import minmax, meanvar, minmax_scale, scale\n",
    "from nnmnkwii import paramgen\n",
    "from nnmnkwii.io import hts\n",
    "from nnmnkwii.frontend import merlin as fe\n",
    "from nnmnkwii.postfilters import merlin_post_filter\n",
    "\n",
    "from os.path import join, expanduser, basename, splitext, basename, exists\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pyworld\n",
    "import pysptk\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython\n",
    "from IPython.display import Audio\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = \"./data/basic5000\"  # NIT-ATR503/\"#\n",
    "test_size = 0.01  # This means 480 utterances for training data\n",
    "random_state = 1234\n",
    "\n",
    "\n",
    "mgc_dim = 180  # メルケプストラム次数　？？\n",
    "lf0_dim = 3  # 対数fo　？？ なんで次元が３？\n",
    "vuv_dim = 1  # 無声or 有声フラグ　？？\n",
    "bap_dim = 15  # 発話ごと非周期成分　？？\n",
    "\n",
    "duration_linguistic_dim = 438  # question_jp.hed で、ラベルに対する言語特徴量をルールベースで記述してる\n",
    "acoustic_linguisic_dim = 442  # 上のやつ+frame_features とは？？\n",
    "duration_dim = 1\n",
    "acoustic_dim = mgc_dim + lf0_dim + vuv_dim + bap_dim  # aoustice modelで求めたいもの\n",
    "\n",
    "fs = 48000\n",
    "frame_period = 5\n",
    "fftlen = pyworld.get_cheaptrick_fft_size(fs)\n",
    "alpha = pysptk.util.mcepalpha(fs)\n",
    "hop_length = int(0.001 * frame_period * fs)\n",
    "\n",
    "mgc_start_idx = 0\n",
    "lf0_start_idx = 180\n",
    "vuv_start_idx = 183\n",
    "bap_start_idx = 184\n",
    "\n",
    "windows = [\n",
    "    (0, 0, np.array([1.0])),\n",
    "    (1, 1, np.array([-0.5, 0.0, 0.5])),\n",
    "    (1, 1, np.array([1.0, -2.0, 1.0])),\n",
    "]\n",
    "\n",
    "use_phone_alignment = True\n",
    "acoustic_subphone_features = \"coarse_coding\" if use_phone_alignment else \"full\"  # とは？\n",
    "\n",
    "\n",
    "from models import BinaryFileSource\n",
    "\n",
    "\n",
    "X = {\"acoustic\": {}}\n",
    "Y = {\"acoustic\": {}}\n",
    "utt_lengths = {\"acoustic\": {}}\n",
    "for ty in [\"acoustic\"]:\n",
    "    for phase in [\"train\", \"test\"]:\n",
    "        train = phase == \"train\"\n",
    "        x_dim = duration_linguistic_dim if ty == \"duration\" else acoustic_linguisic_dim\n",
    "        y_dim = duration_dim if ty == \"duration\" else acoustic_dim\n",
    "        X[ty][phase] = FileSourceDataset(\n",
    "            BinaryFileSource(join(DATA_ROOT, \"X_{}\".format(ty)), dim=x_dim, train=train, valid=False)\n",
    "        )\n",
    "        Y[ty][phase] = FileSourceDataset(\n",
    "            BinaryFileSource(join(DATA_ROOT, \"Y_{}\".format(ty)), dim=y_dim, train=train, valid=False)\n",
    "        )\n",
    "        utt_lengths[ty][phase] = np.array([len(x) for x in X[ty][phase]], dtype=np.int)\n",
    "\n",
    "\"\"\"\n",
    "ここでH/L ラベルをつける処理\n",
    "\"\"\"\n",
    "\n",
    "X_min = {}\n",
    "X_max = {}\n",
    "Y_mean = {}\n",
    "Y_var = {}\n",
    "Y_scale = {}\n",
    "\n",
    "for typ in [\"acoustic\"]:\n",
    "    X_min[typ], X_max[typ] = minmax(X[typ][\"train\"], utt_lengths[typ][\"train\"])\n",
    "    Y_mean[typ], Y_var[typ] = meanvar(Y[typ][\"train\"], utt_lengths[typ][\"train\"])\n",
    "    Y_scale[typ] = np.sqrt(Y_var[typ])\n",
    "\n",
    "\n",
    "from torch.utils import data as data_utils\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tnrange, tqdm\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rnn(nn.Module):\n",
    "    def __init__(self, bidirectional=True, num_layers=2):\n",
    "        super(Rnn, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.num_direction = 2 if bidirectional else 1\n",
    "        ##ここまでエンコーダ\n",
    "\n",
    "        self.fc11 = nn.Linear(acoustic_linguisic_dim+1, acoustic_linguisic_dim+1)\n",
    "\n",
    "        self.lstm2 = nn.LSTM(\n",
    "            acoustic_linguisic_dim+1, 512, num_layers, bidirectional=bidirectional\n",
    "        )\n",
    "        self.fc3 = nn.Linear(self.num_direction * 512, 1)\n",
    "\n",
    "    def decode(self, linguistic_features):\n",
    "        x = self.fc11(linguistic_features.view(linguistic_features.size()[0], 1, -1))\n",
    "        x = F.relu(x)\n",
    "        h3, (h, c) = self.lstm2(x)\n",
    "        h3 = F.relu(h3)\n",
    "\n",
    "        return self.fc3(h3)  # torch.sigmoid(self.fc3(h3))\n",
    "\n",
    "    def forward(self, linguistic_features):\n",
    "\n",
    "        return self.decode(linguistic_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_l_labels_train = []\n",
    "h_l_labels_test = []\n",
    "for i in range(5000):\n",
    "    h_l_label = np.loadtxt(\"./data/basic5000/accents/accents_\" + \"0\" * (4 - len(str(i + 1))) + str(i + 1) + \".csv\",)\n",
    "    if (i-1) % 20 == 0:\n",
    "        h_l_labels_test.append(h_l_label)\n",
    "    elif (i - 1) % 20 != 0:\n",
    "        h_l_labels_train.append(h_l_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import smooth_f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_acoustic_train = [\n",
    "    minmax_scale(x, X_min[\"acoustic\"], X_max[\"acoustic\"], feature_range=(0.01, 0.99))\n",
    "    for x in X[\"acoustic\"][\"train\"]\n",
    "]\n",
    "Y_acoustic_train = [smooth_f0(y) for y in Y[\"acoustic\"][\"train\"]]\n",
    "\n",
    "\n",
    "X_acoustic_test = [\n",
    "    minmax_scale(x, X_min[\"acoustic\"], X_max[\"acoustic\"], feature_range=(0.01, 0.99))\n",
    "    for x in X[\"acoustic\"][\"test\"]\n",
    "]\n",
    "Y_acoustic_test = [smooth_f0(y) for y in Y[\"acoustic\"][\"test\"]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = [\n",
    "    [x, y, l_h_label]\n",
    "    for x, y, l_h_label in zip(X_acoustic_train, Y_acoustic_train, h_l_labels_train)\n",
    "]\n",
    "test_loader = [\n",
    "    [x, y,l_h_label]\n",
    "    for x, y, l_h_label in zip(X_acoustic_test, Y_acoustic_test, h_l_labels_test)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mora_index_lists = sorted(glob(join(\"data/basic5000/mora_index\", \"squeezed_*.csv\")))\n",
    "mora_index_lists_for_model = [np.loadtxt(path).reshape(-1) for path in mora_index_lists]\n",
    "train_mora_index_lists = []\n",
    "test_mora_index_lists = []\n",
    "test_not_valid = []\n",
    "\n",
    "for i, mora_i in enumerate(mora_index_lists_for_model):\n",
    "    if (i - 1) % 20 == 0:  # test\n",
    "        test_mora_index_lists.append(mora_i)\n",
    "    elif i % 20 == 0:  # valid\n",
    "        pass\n",
    "        #test_mora_index_lists.append(mora_i)\n",
    "    else:\n",
    "        train_mora_index_lists.append(mora_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Rnn()\n",
    "model.load_state_dict(torch.load('../../disk/baseline2/baseline_3.pth', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recon(index, model=model, z0=False, verbose=True):\n",
    "    with torch.no_grad():\n",
    "        tmp = []\n",
    "        data = test_loader[index]\n",
    "        for j in range(3):\n",
    "            tmp.append(torch.from_numpy(data[j]))\n",
    "        \n",
    "        \n",
    "        h_l_label_tensor = torch.tensor([0] * data[0].shape[0])\n",
    "        \n",
    " \n",
    "        if not z0:\n",
    "            for j, mora_i in enumerate(test_mora_index_lists[index]):\n",
    "                prev_index = 0 if j == 0 else int(test_mora_index_lists[index][j - 1])\n",
    "                h_l_label_tensor[prev_index : int(mora_i)] = tmp[2][j]\n",
    "\n",
    "            h_l_label_tensor[(data[0][:, 97] - 0.01).nonzero()[0]] = 0\n",
    "        if verbose:\n",
    "            plt.plot(data[1][:, lf0_start_idx])\n",
    "            plt.plot(h_l_label_tensor.numpy())\n",
    "\n",
    "            \n",
    "        x = torch.cat([tmp[0].float(), h_l_label_tensor.float().view(-1, 1).repeat_interleave(1, dim=1)], dim=1)\n",
    "        \n",
    "        y = model(x)\n",
    "        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "for i in range(443):\n",
    "    means.append(model.fc11.weight[:, i].mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(means).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_parameters(y_predicted, verbose=True):\n",
    "    # Number of time frames\n",
    "    T = y_predicted.shape[0]\n",
    "    \n",
    "    # Split acoustic features\n",
    "    mgc = y_predicted[:,:lf0_start_idx]\n",
    "    lf0 = y_predicted[:,lf0_start_idx:vuv_start_idx]\n",
    "    if verbose:\n",
    "        plt.plot(lf0[:, 0])\n",
    "        plt.show()\n",
    "    #lf0 = Y['acoustic']['train'][90][:, lf0_start_idx:vuv_start_idx]\n",
    "    #lf0 = np.zeros(lf0.shape)\n",
    "    vuv = y_predicted[:,vuv_start_idx]\n",
    "\n",
    "    bap = y_predicted[:,bap_start_idx:]\n",
    "    \n",
    "    # Perform MLPG\n",
    "    ty = \"acoustic\"\n",
    "    mgc_variances = np.tile(Y_var[ty][:lf0_start_idx], (T, 1))#np.tile(np.ones(Y_var[ty][:lf0_start_idx].shape), (T, 1))#\n",
    "    mgc = paramgen.mlpg(mgc, mgc_variances, windows)\n",
    "    lf0_variances = np.tile(Y_var[ty][lf0_start_idx:vuv_start_idx], (T,1))#np.tile(np.ones(Y_var[ty][lf0_start_idx:vuv_start_idx].shape), (T,1))#\n",
    "    lf0 = paramgen.mlpg(lf0, lf0_variances, windows)\n",
    "    bap_variances = np.tile(Y_var[ty][bap_start_idx:], (T, 1))#np.tile(np.ones(Y_var[ty][bap_start_idx:].shape), (T, 1))#\n",
    "    bap = paramgen.mlpg(bap, bap_variances, windows)\n",
    "    \n",
    "    return mgc, lf0, vuv, bap\n",
    "def gen_waveform(y_predicted, do_postfilter=False, verbose=True):  \n",
    "    y_predicted = trim_zeros_frames(y_predicted)\n",
    "        \n",
    "    # Generate parameters and split streams\n",
    "    mgc, lf0, vuv, bap = gen_parameters(y_predicted, verbose=verbose)\n",
    "    \n",
    "    if do_postfilter:\n",
    "        mgc = merlin_post_filter(mgc, alpha)\n",
    "        \n",
    "    spectrogram = pysptk.mc2sp(mgc, fftlen=fftlen, alpha=alpha)\n",
    "    aperiodicity = pyworld.decode_aperiodicity(bap.astype(np.float64), fs, fftlen)\n",
    "    f0 = lf0.copy()\n",
    "    f0[vuv < 0.5] = 0\n",
    "    f0[np.nonzero(f0)] = np.exp(f0[np.nonzero(f0)])\n",
    "    \n",
    "    generated_waveform = pyworld.synthesize(f0.flatten().astype(np.float64),\n",
    "                                            spectrogram.astype(np.float64),\n",
    "                                            aperiodicity.astype(np.float64),\n",
    "                                            fs, frame_period)\n",
    "    return generated_waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize(index, model=model, z0=False):\n",
    "    y = recon(index, model=model, z0=z0).numpy().reshape(-1)\n",
    "    y_base = test_loader[index][1].copy()\n",
    "    y_base[:, lf0_start_idx] = y\n",
    "    y_base[:, lf0_start_idx+1:lf0_start_idx+3] = 0\n",
    "    IPython.display.display(Audio(gen_waveform(y_base, True), rate=fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(A, B):\n",
    "    return np.sqrt((np.square(A - B)).mean())\n",
    "\n",
    "def calc_lf0_rmse(natural, generated, lf0_idx=lf0_start_idx, vuv_idx=vuv_start_idx):\n",
    "    idx = (natural[:, vuv_idx]).astype(bool)\n",
    "    return rmse(natural[idx, lf0_idx], generated[idx]) * 1200 / np.log(2)  # unit: [cent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.display(Audio(gen_waveform(test_loader[90][1], True), rate=fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesize(0, )\n",
    "synthesize(0, z0=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_error = 0\n",
    "savedir = '../../disk/asj_vae/data/basic5000/generated/baseline_u3'\n",
    "for i, data in tqdm(enumerate(test_loader)):\n",
    "    y = recon(i).view(-1).numpy()\n",
    "    y_base = data[1].copy()\n",
    "    y_base[:, lf0_start_idx] = y\n",
    "    y_base[:, lf0_start_idx+1:lf0_start_idx+3] = 0\n",
    "    waveform = gen_waveform(y_base, True, verbose=False)\n",
    "    wavfile.write(join(savedir, 'BASIC5000_{}{}.wav'.format('0'*(4-len(str(i+1))), i+1)), rate=fs, data=waveform.astype(np.int16))\n",
    "    f0_error += calc_lf0_rmse(data[1], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_error = 0\n",
    "savedir = '../../disk/asj_vae/data/basic5000/generated/baseline_u3_z0'\n",
    "for i, data in tqdm(enumerate(test_loader)):\n",
    "    y = recon(i, verbose=False, z0=True).view(-1).numpy()\n",
    "    y_base = data[1].copy()\n",
    "    y_base[:, lf0_start_idx] = y\n",
    "    y_base[:, lf0_start_idx+1:lf0_start_idx+3] = 0\n",
    "    waveform = gen_waveform(y_base, True, verbose=False)\n",
    "    wavfile.write(join(savedir, 'BASIC5000_{}{}_0.wav'.format('0'*(4-len(str(i+1))), i+1)), rate=fs, data=waveform.astype(np.int16))\n",
    "    f0_error += calc_lf0_rmse(data[1], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_error = 0\n",
    "for i, data in tqdm(enumerate(test_loader)):\n",
    "    y = recon(i, verbose=False).view(-1).numpy()\n",
    "    y_true = data[1]\n",
    "    f0_error += calc_lf0_rmse(y_true, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_error / 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_error = 0\n",
    "for i, data in tqdm(enumerate(test_loader)):\n",
    "    y = recon(i, z0=True, verbose=False).view(-1).numpy()\n",
    "    y_true = data[1]\n",
    "    f0_error += calc_lf0_rmse(y_true, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_error / 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyRNN(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out, num_layers=1, bidirectional=True):\n",
    "        super(MyRNN, self).__init__()\n",
    "        self.hidden_dim = H\n",
    "        self.num_layers = num_layers\n",
    "        self.num_direction =  2 if bidirectional else 1\n",
    "        self.lstm = nn.LSTM(D_in, H, num_layers, bidirectional=bidirectional, batch_first=True)\n",
    "        self.hidden2out = nn.Linear(self.num_direction*self.hidden_dim, D_out)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        h, c = (Variable(torch.zeros(self.num_layers * self.num_direction, batch_size, self.hidden_dim)), \n",
    "                Variable(torch.zeros(self.num_layers * self.num_direction, batch_size, self.hidden_dim)))\n",
    "        return h,c\n",
    "\n",
    "    def forward(self, sequence):\n",
    "        h, c = self.init_hidden(1)\n",
    "        output, (h, c) = self.lstm(sequence.view(1, -1, 535), (h, c))\n",
    "        output = self.hidden2out(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesize(0, model=model_no_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
